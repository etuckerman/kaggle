{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bd7cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:05:49.378049Z",
     "iopub.status.busy": "2024-09-03T20:05:49.377688Z",
     "iopub.status.idle": "2024-09-03T20:09:45.477163Z",
     "shell.execute_reply": "2024-09-03T20:09:45.476357Z"
    },
    "papermill": {
     "duration": 236.107462,
     "end_time": "2024-09-03T20:09:45.479536",
     "exception": false,
     "start_time": "2024-09-03T20:05:49.372074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon\r\n",
      "  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.features==1.1.1 (from autogluon)\r\n",
      "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting autogluon.multimodal==1.1.1 (from autogluon)\r\n",
      "  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\r\n",
      "Collecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\r\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\r\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\r\n",
      "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\r\n",
      "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\r\n",
      "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\r\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\r\n",
      "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\r\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\r\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\r\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\r\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.16.2)\r\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\r\n",
      "Requirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\r\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.16)\r\n",
      "Requirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\r\n",
      "Requirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\r\n",
      "Requirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\r\n",
      "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.10.4)\r\n",
      "Collecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (70.0.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.8.2)\r\n",
      "Requirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.2)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.21.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.6.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.24.6)\r\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.0)\r\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\r\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.55)\r\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (3.0.0)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.18.1)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.6)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\r\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.5.15)\r\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\r\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\r\n",
      "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.13.2)\r\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.2)\r\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.15.1)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.8)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\r\n",
      "Requirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.5)\r\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\r\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\r\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\r\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\r\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\r\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.2)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.7.4)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.34.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.5.22)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.6.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\r\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.4)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.20.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.3)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\r\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\r\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\r\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\r\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.3.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.16.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.63.1)\r\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.30.0)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.4)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.18.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\r\n",
      "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\r\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\r\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.9)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.6.0)\r\n",
      "Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\r\n",
      "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\r\n",
      "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\r\n",
      "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\r\n",
      "Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\r\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\r\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=189ead8e3e2f0f464164f77264a6b7955690c7f15ed4af9c701527d438eb347e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b7a5c7b64dd2eb98fc8232c52ba34dafe5dc54dcc99ad2254123d047ae25d1c7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=2cdbad96a318e676a6a34b26ea54011391d87f6c63b2f9525f4345504539b192\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\r\n",
      "Installing collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, scipy, Pillow, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, model-index, humanfriendly, window-ops, scikit-learn, pytesseract, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, jsonschema, gluonts, gdown, aiohttp-cors, transformers, torch, statsforecast, ray, openmim, nlpaug, mlforecast, torchvision, torchmetrics, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, pytorch-lightning, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.14.0\r\n",
      "    Uninstalling scipy-1.14.0:\r\n",
      "      Successfully uninstalled scipy-1.14.0\r\n",
      "  Attempting uninstall: Pillow\r\n",
      "    Found existing installation: Pillow 9.5.0\r\n",
      "    Uninstalling Pillow-9.5.0:\r\n",
      "      Successfully uninstalled Pillow-9.5.0\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: pytesseract\r\n",
      "    Found existing installation: pytesseract 0.3.13\r\n",
      "    Uninstalling pytesseract-0.3.13:\r\n",
      "      Successfully uninstalled pytesseract-0.3.13\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.34.131\r\n",
      "    Uninstalling botocore-1.34.131:\r\n",
      "      Successfully uninstalled botocore-1.34.131\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.19.1\r\n",
      "    Uninstalling tokenizers-0.19.1:\r\n",
      "      Successfully uninstalled tokenizers-0.19.1\r\n",
      "  Attempting uninstall: scikit-image\r\n",
      "    Found existing installation: scikit-image 0.23.2\r\n",
      "    Uninstalling scikit-image-0.23.2:\r\n",
      "      Successfully uninstalled scikit-image-0.23.2\r\n",
      "  Attempting uninstall: jsonschema\r\n",
      "    Found existing installation: jsonschema 4.22.0\r\n",
      "    Uninstalling jsonschema-4.22.0:\r\n",
      "      Successfully uninstalled jsonschema-4.22.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.44.0\r\n",
      "    Uninstalling transformers-4.44.0:\r\n",
      "      Successfully uninstalled transformers-4.44.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0\r\n",
      "    Uninstalling torch-2.4.0:\r\n",
      "      Successfully uninstalled torch-2.4.0\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.24.0\r\n",
      "    Uninstalling ray-2.24.0:\r\n",
      "      Successfully uninstalled ray-2.24.0\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.19.0\r\n",
      "    Uninstalling torchvision-0.19.0:\r\n",
      "      Successfully uninstalled torchvision-0.19.0\r\n",
      "  Attempting uninstall: torchmetrics\r\n",
      "    Found existing installation: torchmetrics 1.4.1\r\n",
      "    Uninstalling torchmetrics-1.4.1:\r\n",
      "      Successfully uninstalled torchmetrics-1.4.1\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 0.33.0\r\n",
      "    Uninstalling accelerate-0.33.0:\r\n",
      "      Successfully uninstalled accelerate-0.33.0\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.8\r\n",
      "    Uninstalling timm-1.0.8:\r\n",
      "      Successfully uninstalled timm-1.0.8\r\n",
      "  Attempting uninstall: pytorch-lightning\r\n",
      "    Found existing installation: pytorch-lightning 2.4.0\r\n",
      "    Uninstalling pytorch-lightning-2.4.0:\r\n",
      "      Successfully uninstalled pytorch-lightning-2.4.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "aiobotocore 2.13.2 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\r\n",
      "albumentations 1.4.14 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\r\n",
      "jupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed Pillow-10.4.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 botocore-1.29.165 coloredlogs-15.0.1 evaluate-0.4.2 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 jsonschema-4.21.1 lightning-2.3.3 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.9.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.19.0 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 scikit-learn-1.4.0 scipy-1.12.0 seqeval-1.2.2 statsforecast-1.4.0 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\r\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00c5434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:09:45.665171Z",
     "iopub.status.busy": "2024-09-03T20:09:45.664384Z",
     "iopub.status.idle": "2024-09-03T20:10:02.469622Z",
     "shell.execute_reply": "2024-09-03T20:10:02.468660Z"
    },
    "papermill": {
     "duration": 16.900308,
     "end_time": "2024-09-03T20:10:02.472030",
     "exception": false,
     "start_time": "2024-09-03T20:09:45.571722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lightgbm 4.2.0\r\n",
      "Uninstalling lightgbm-4.2.0:\r\n",
      "  Successfully uninstalled lightgbm-4.2.0\r\n",
      "Collecting lightgbm\r\n",
      "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.12.0)\r\n",
      "Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lightgbm\r\n",
      "Successfully installed lightgbm-4.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall lightgbm -y\n",
    "!pip install lightgbm --no-cache-dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f74780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:10:02.667462Z",
     "iopub.status.busy": "2024-09-03T20:10:02.666620Z",
     "iopub.status.idle": "2024-09-03T20:10:05.072736Z",
     "shell.execute_reply": "2024-09-03T20:10:05.071714Z"
    },
    "papermill": {
     "duration": 2.50683,
     "end_time": "2024-09-03T20:10:05.074955",
     "exception": false,
     "start_time": "2024-09-03T20:10:02.568125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover LR2 Base</td>\n",
       "      <td>2015</td>\n",
       "      <td>98000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>6-Speed A/T</td>\n",
       "      <td>White</td>\n",
       "      <td>Beige</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188534</td>\n",
       "      <td>Land</td>\n",
       "      <td>Rover Defender SE</td>\n",
       "      <td>2020</td>\n",
       "      <td>9142</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n",
       "      <td>8-Speed A/T</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188535</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Expedition Limited</td>\n",
       "      <td>2022</td>\n",
       "      <td>28121</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n",
       "      <td>10-Speed Automatic</td>\n",
       "      <td>White</td>\n",
       "      <td>Ebony</td>\n",
       "      <td>None reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188536</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A6 2.0T Sport</td>\n",
       "      <td>2016</td>\n",
       "      <td>61258</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>2.0 Liter TFSI</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Silician Yellow</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188537</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A6 2.0T Premium Plus</td>\n",
       "      <td>2018</td>\n",
       "      <td>59000</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Black</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id brand                 model  model_year  milage fuel_type  \\\n",
       "0  188533  Land        Rover LR2 Base        2015   98000  Gasoline   \n",
       "1  188534  Land     Rover Defender SE        2020    9142    Hybrid   \n",
       "2  188535  Ford    Expedition Limited        2022   28121  Gasoline   \n",
       "3  188536  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n",
       "4  188537  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n",
       "\n",
       "                                              engine        transmission  \\\n",
       "0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n",
       "1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n",
       "2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n",
       "3                                     2.0 Liter TFSI           Automatic   \n",
       "4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n",
       "\n",
       "           ext_col int_col       accident clean_title  \n",
       "0            White   Beige  None reported         Yes  \n",
       "1           Silver   Black  None reported         Yes  \n",
       "2            White   Ebony  None reported         NaN  \n",
       "3  Silician Yellow   Black  None reported         NaN  \n",
       "4             Gray   Black  None reported         Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81582c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:10:05.301522Z",
     "iopub.status.busy": "2024-09-03T20:10:05.300651Z",
     "iopub.status.idle": "2024-09-03T20:10:42.856511Z",
     "shell.execute_reply": "2024-09-03T20:10:42.855649Z"
    },
    "papermill": {
     "duration": 37.689572,
     "end_time": "2024-09-03T20:10:42.858775",
     "exception": false,
     "start_time": "2024-09-03T20:10:05.169203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract horsepower and engine size from the 'engine' column\n",
    "def extract_engine_features(engine_str):\n",
    "    try:\n",
    "        hp = float(engine_str.split('HP')[0].split()[-1])\n",
    "        size = float(engine_str.split('L')[0].split()[-1])\n",
    "    except ValueError:\n",
    "        hp, size = None, None\n",
    "    return pd.Series([hp, size])\n",
    "\n",
    "train_df[['engine_hp', 'engine_size']] = train_df['engine'].apply(extract_engine_features)\n",
    "test_df[['engine_hp', 'engine_size']] = test_df['engine'].apply(extract_engine_features)\n",
    "\n",
    "# Drop the 'engine' column after feature extraction\n",
    "train_df = train_df.drop(columns=['engine'])\n",
    "test_df = test_df.drop(columns=['engine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15016ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:10:43.056707Z",
     "iopub.status.busy": "2024-09-03T20:10:43.055887Z",
     "iopub.status.idle": "2024-09-03T20:10:43.697137Z",
     "shell.execute_reply": "2024-09-03T20:10:43.696059Z"
    },
    "papermill": {
     "duration": 0.747886,
     "end_time": "2024-09-03T20:10:43.699211",
     "exception": false,
     "start_time": "2024-09-03T20:10:42.951325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3929515891.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_23/3929515891.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_23/3929515891.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
      "/tmp/ipykernel_23/3929515891.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in train_df (including the 'price' column)\n",
    "for col in train_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "\n",
    "# Handle missing values in test_df (excluding the 'price' column, since it doesn't exist)\n",
    "for col in test_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values in categorical columns with the most frequent value for both train_df and test_df\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "\n",
    "for col in test_df.select_dtypes(include=['object']).columns:\n",
    "    test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb40bd90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:10:43.886129Z",
     "iopub.status.busy": "2024-09-03T20:10:43.885387Z",
     "iopub.status.idle": "2024-09-03T20:10:44.135640Z",
     "shell.execute_reply": "2024-09-03T20:10:44.134866Z"
    },
    "papermill": {
     "duration": 0.34518,
     "end_time": "2024-09-03T20:10:44.137883",
     "exception": false,
     "start_time": "2024-09-03T20:10:43.792703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtype\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc9781e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:10:44.326212Z",
     "iopub.status.busy": "2024-09-03T20:10:44.325486Z",
     "iopub.status.idle": "2024-09-03T20:20:46.556776Z",
     "shell.execute_reply": "2024-09-03T20:20:46.555852Z"
    },
    "papermill": {
     "duration": 602.327566,
     "end_time": "2024-09-03T20:20:46.558939",
     "exception": false,
     "start_time": "2024-09-03T20:10:44.231373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240903_201044\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "GPU Count:          2\n",
      "Memory Avail:       30.00 GB / 31.36 GB (95.7%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 2},\n",
      " 'auto_stack': True,\n",
      " 'excluded_model_types': ['KNN'],\n",
      " 'num_bag_sets': 1,\n",
      " 'verbosity': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 2},\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': ['KNN'],\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "2024-09-03 20:10:46,527\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-09-03 20:10:49,467\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Beginning AutoGluon training ... Time limit = 145s\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Train Data Rows:    167584\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Train Data Columns: 13\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Label Column:       price\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tAvailable Memory:                    30114.64 MB\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTrain Data (Original)  Memory Usage: 8.32 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', 'category') : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', []) : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])    : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])      : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tUseless Original Features (Count: 1): ['clean_title']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('category', 'category') : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('category', []) : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('float', [])    : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int', [])      : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('category', 'category') : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int8', 'int')          : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t\t('int', ['bool']) : 1 | ['accident']\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.4s = Fit runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTrain Data (Processed) Memory Usage: 7.99 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Data preprocessing and feature engineering runtime = 0.43s ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting 106 L1 models ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 96.48s of the 144.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.21%)\n",
      "\u001b[36m(_ray_fit pid=564)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=564)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=564)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=564)\u001b[0m [50]\tvalid_set's rmse: 82256\n",
      "\u001b[36m(_ray_fit pid=564)\u001b[0m [100]\tvalid_set's rmse: 82201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=593)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=593)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=593)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=593)\u001b[0m [50]\tvalid_set's rmse: 83184.1\n",
      "\u001b[36m(_ray_fit pid=593)\u001b[0m [100]\tvalid_set's rmse: 83064.9\n",
      "\u001b[36m(_ray_fit pid=593)\u001b[0m [150]\tvalid_set's rmse: 82974\n",
      "\u001b[36m(_ray_fit pid=593)\u001b[0m [200]\tvalid_set's rmse: 82950.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=622)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=622)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=622)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=622)\u001b[0m [50]\tvalid_set's rmse: 69848.1\n",
      "\u001b[36m(_ray_fit pid=622)\u001b[0m [100]\tvalid_set's rmse: 69955.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=651)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=651)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=651)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=651)\u001b[0m [50]\tvalid_set's rmse: 79012.2\n",
      "\u001b[36m(_ray_fit pid=651)\u001b[0m [100]\tvalid_set's rmse: 78849.4\n",
      "\u001b[36m(_ray_fit pid=651)\u001b[0m [150]\tvalid_set's rmse: 78822.9\n",
      "\u001b[36m(_ray_fit pid=651)\u001b[0m [200]\tvalid_set's rmse: 78845.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=680)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=680)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=680)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=680)\u001b[0m [50]\tvalid_set's rmse: 67553.4\n",
      "\u001b[36m(_ray_fit pid=680)\u001b[0m [100]\tvalid_set's rmse: 67516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=709)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=709)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=709)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=709)\u001b[0m [50]\tvalid_set's rmse: 69528.4\n",
      "\u001b[36m(_ray_fit pid=709)\u001b[0m [100]\tvalid_set's rmse: 69409.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=738)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=738)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=738)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=738)\u001b[0m [50]\tvalid_set's rmse: 62106.6\n",
      "\u001b[36m(_ray_fit pid=738)\u001b[0m [100]\tvalid_set's rmse: 62083.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=767)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=767)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=767)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=767)\u001b[0m [50]\tvalid_set's rmse: 70889.9\n",
      "\u001b[36m(_ray_fit pid=767)\u001b[0m [100]\tvalid_set's rmse: 70889.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t-73256.8382\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t54.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t1.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t15621.9\t = Inference  throughput (rows/s | 20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 36.52s of the 84.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.21%)\n",
      "\u001b[36m(_ray_fit pid=880)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=880)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=880)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=880)\u001b[0m [50]\tvalid_set's rmse: 82384.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=909)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=909)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=909)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=909)\u001b[0m [50]\tvalid_set's rmse: 83399.4\n",
      "\u001b[36m(_ray_fit pid=909)\u001b[0m [100]\tvalid_set's rmse: 83115.9\n",
      "\u001b[36m(_ray_fit pid=909)\u001b[0m [150]\tvalid_set's rmse: 83040.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=909)\u001b[0m \tRan out of time, early stopping on iteration 183. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=909)\u001b[0m \t[166]\tvalid_set's rmse: 82991.3\n",
      "\u001b[36m(_ray_fit pid=938)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=938)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=938)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=938)\u001b[0m [50]\tvalid_set's rmse: 70357.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=967)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=967)\u001b[0m [50]\tvalid_set's rmse: 79339.7\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m [100]\tvalid_set's rmse: 79278.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=996)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=996)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=996)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=996)\u001b[0m [50]\tvalid_set's rmse: 67888.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1025)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1025)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1025)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1025)\u001b[0m [50]\tvalid_set's rmse: 69935.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1054)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1054)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1054)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1054)\u001b[0m [50]\tvalid_set's rmse: 62675.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1083)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1083)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1083)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1083)\u001b[0m [50]\tvalid_set's rmse: 71391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t-73642.1813\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t49.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.68s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t31016.2\t = Inference  throughput (rows/s | 20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForestMSE_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTreesMSE_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 144.76s of the 33.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Ensemble size: 5\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=275)\u001b[0m [0.8 0.2]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.34s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'LightGBM_BAG_L1': 0.2}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t-73230.8882\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t10387.7\t = Inference  throughput (rows/s | 20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting 106 L2 models ...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 33.1s of the 33.06s of remaining time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.24%)\n",
      "\u001b[36m(_ray_fit pid=1202)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1202)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1202)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1202)\u001b[0m [50]\tvalid_set's rmse: 72245.3\n",
      "\u001b[36m(_ray_fit pid=1202)\u001b[0m [100]\tvalid_set's rmse: 72216.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m [50]\tvalid_set's rmse: 64021.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1260)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1260)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1260)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1260)\u001b[0m [50]\tvalid_set's rmse: 59974.3\n",
      "\u001b[36m(_ray_fit pid=1260)\u001b[0m [100]\tvalid_set's rmse: 59904.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1289)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1289)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1289)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1289)\u001b[0m [50]\tvalid_set's rmse: 79112.9\n",
      "\u001b[36m(_ray_fit pid=1289)\u001b[0m [100]\tvalid_set's rmse: 79139.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1318)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1318)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1318)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1318)\u001b[0m [50]\tvalid_set's rmse: 74162.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1347)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1347)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1347)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1347)\u001b[0m [50]\tvalid_set's rmse: 75223.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1376)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1376)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1376)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1376)\u001b[0m [50]\tvalid_set's rmse: 76387.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1405)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1405)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n",
      "\u001b[36m(_ray_fit pid=1405)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1405)\u001b[0m [50]\tvalid_set's rmse: 82418.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t-73240.5392\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t50.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.77s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t7510.7\t = Inference  throughput (rows/s | 20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForestMSE_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTreesMSE_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 144.76s of the -20.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Ensemble size: 21\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=275)\u001b[0m [0.38095238 0.14285714 0.47619048]\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.53s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.476, 'LightGBMXT_BAG_L1': 0.381, 'LightGBM_BAG_L1': 0.143}\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t-73189.5214\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m \t7509.9\t = Inference  throughput (rows/s | 20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m AutoGluon training complete, total runtime = 165.61s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 7509.9 rows/s (20948 batch size)\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.1.1\"\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Saving AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/metadata.json\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Loading: AutogluonModels/ag-20240903_201044/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
      "\u001b[36m(_dystack pid=275)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout     score_val              eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L3  -69931.080981 -73189.521360  root_mean_squared_error        1.319489       2.791484  155.011275                 0.003224                0.002383           0.116308            3       True          5\n",
      "1    LightGBMXT_BAG_L2  -69939.096165 -73240.539242  root_mean_squared_error        1.316265       2.789100  154.894967                 0.319463                0.772770          50.913678            2       True          4\n",
      "2  WeightedEnsemble_L2  -69964.131964 -73230.888200  root_mean_squared_error        0.999568       2.018569  104.079023                 0.002766                0.002239           0.097733            2       True          3\n",
      "3    LightGBMXT_BAG_L1  -70001.086374 -73256.838170  root_mean_squared_error        0.643098       1.340941   54.611043                 0.643098                1.340941          54.611043            1       True          1\n",
      "4      LightGBM_BAG_L1  -70149.966146 -73642.181257  root_mean_squared_error        0.353704       0.675389   49.370247                 0.353704                0.675389          49.370247            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t174s\t = DyStack   runtime |\t426s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Saving AutogluonModels/ag-20240903_201044/learner.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 426s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240903_201044\"\n",
      "Train Data Rows:    188533\n",
      "Train Data Columns: 13\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29952.20 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('category', 'category') : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])    : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])      : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t0.0s = Fit runtime\n",
      "\t\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\tUseless Original Features (Count: 1): ['clean_title']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('float', [])    : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t('int', [])      : 3 | ['id', 'model_year', 'milage']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('float64', 'float')     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t('int64', 'int')         : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int8', 'int')          : 1 | ['accident']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "\t\t('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int', ['bool']) : 1 | ['accident']\n",
      "\t0.5s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.99 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving AutogluonModels/ag-20240903_201044/learner.pkl\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Saving AutogluonModels/ag-20240903_201044/utils/data/X.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/utils/data/y.pkl\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "Fitting 106 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 283.54s of the 425.29s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.20%)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-72879.5774\t = Validation score   (-root_mean_squared_error)\n",
      "\t56.71s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "\t16512.7\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 222.92s of the 364.67s of remaining time.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.20%)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-73158.4217\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.44s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "\t34266.1\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 169.36s of the 311.12s of remaining time.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\t34.8s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-77194.9011\t = Validation score   (-root_mean_squared_error)\n",
      "\t120.37s\t = Training   runtime\n",
      "\t6.53s\t = Validation runtime\n",
      "\t28879.6\t = Inference  throughput (rows/s | 188533 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 41.29s of the 183.05s of remaining time.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.21%)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-76402.0323\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.86s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "\t142147.4\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.38s of the 143.13s of remaining time.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\t33.79s\t= Estimated out-of-fold prediction time...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 33.79s compared to 10s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 113.43s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 17\n",
      "Ensemble weights: \n",
      "[0.70588235 0.23529412 0.05882353 0.        ]\n",
      "\t0.85s\t= Estimated out-of-fold prediction time...\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.706, 'LightGBM_BAG_L1': 0.235, 'RandomForestMSE_BAG_L1': 0.059}\n",
      "\t-72821.8256\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t8039.5\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_fit': {'num_gpus': 2}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "\tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}, 'ag_args_fit': {'num_gpus': 2}}\n",
      "Fitting 106 L2 models ...\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 113.23s of the 113.05s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.26%)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-72819.6719\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.29s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "\t5995.0\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 55.78s of the 55.59s of remaining time.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=2, memory=0.26%)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-73196.0136\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.65s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "\t6628.6\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForestMSE_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTreesMSE_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.15s of remaining time.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Ensemble size: 25\n",
      "Ensemble weights: \n",
      "[0.28 0.16 0.04 0.   0.48 0.04]\n",
      "\t0.84s\t= Estimated out-of-fold prediction time...\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/model.pkl\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.48, 'LightGBMXT_BAG_L1': 0.28, 'LightGBM_BAG_L1': 0.16, 'RandomForestMSE_BAG_L1': 0.04, 'LightGBM_BAG_L2': 0.04}\n",
      "\t-72768.3363\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t5368.3\t = Inference  throughput (rows/s | 23567 batch size)\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 426.09s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 5368.3 rows/s (23567 batch size)\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/learner.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/predictor.pkl\n",
      "Saving AutogluonModels/ag-20240903_201044/version.txt with contents \"1.1.1\"\n",
      "Saving AutogluonModels/ag-20240903_201044/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240903_201044\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='price', eval_metric='rmse').fit(\n",
    "    train_df,\n",
    "    presets='best_quality',\n",
    "    time_limit=600,  # 10 minutes\n",
    "    verbosity=3,  # More detailed output\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={'num_gpus': 2}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82d82f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:20:46.919601Z",
     "iopub.status.busy": "2024-09-03T20:20:46.918517Z",
     "iopub.status.idle": "2024-09-03T20:20:47.686806Z",
     "shell.execute_reply": "2024-09-03T20:20:47.685864Z"
    },
    "papermill": {
     "duration": 0.947869,
     "end_time": "2024-09-03T20:20:47.689329",
     "exception": false,
     "start_time": "2024-09-03T20:20:46.741460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                    model     score_val              eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L3 -72768.336340  root_mean_squared_error      10.104682  374.546050                0.002832           0.210679            3       True          8\n",
      "1       LightGBMXT_BAG_L2 -72819.671931  root_mean_squared_error       9.643301  321.681062                0.834290          55.293656            2       True          6\n",
      "2     WeightedEnsemble_L2 -72821.825567  root_mean_squared_error       8.646410  228.687319                0.003193           0.159864            2       True          5\n",
      "3       LightGBMXT_BAG_L1 -72879.577450  root_mean_squared_error       1.427207   56.714458                1.427207          56.714458            1       True          1\n",
      "4         LightGBM_BAG_L1 -73158.421654  root_mean_squared_error       0.687765   51.438272                0.687765          51.438272            1       True          2\n",
      "5         LightGBM_BAG_L2 -73196.013646  root_mean_squared_error       9.267560  319.041714                0.458549          52.654309            2       True          7\n",
      "6         CatBoost_BAG_L1 -76402.032339  root_mean_squared_error       0.165793   37.859951                0.165793          37.859951            1       True          4\n",
      "7  RandomForestMSE_BAG_L1 -77194.901115  root_mean_squared_error       6.528245  120.374725                6.528245         120.374725            1       True          3\n",
      "Number of models trained: 8\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "('float', [])     : 2 | ['engine_hp', 'engine_size']\n",
      "('int', [])       : 3 | ['id', 'model_year', 'milage']\n",
      "('int', ['bool']) : 1 | ['accident']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20240903_201044SummaryOfModels.html\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB', 'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF', 'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost', 'WeightedEnsemble_L2': 'WeightedEnsembleModel', 'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB', 'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB', 'WeightedEnsemble_L3': 'WeightedEnsembleModel'}, 'model_performance': {'LightGBMXT_BAG_L1': -72879.57744987354, 'LightGBM_BAG_L1': -73158.42165370949, 'RandomForestMSE_BAG_L1': -77194.90111503367, 'CatBoost_BAG_L1': -76402.03233854254, 'WeightedEnsemble_L2': -72821.82556690145, 'LightGBMXT_BAG_L2': -72819.67193142528, 'LightGBM_BAG_L2': -73196.01364601948, 'WeightedEnsemble_L3': -72768.33634049213}, 'model_best': 'WeightedEnsemble_L3', 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'], 'LightGBM_BAG_L1': ['LightGBM_BAG_L1'], 'RandomForestMSE_BAG_L1': ['RandomForestMSE_BAG_L1'], 'CatBoost_BAG_L1': ['CatBoost_BAG_L1'], 'WeightedEnsemble_L2': ['WeightedEnsemble_L2'], 'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'], 'LightGBM_BAG_L2': ['LightGBM_BAG_L2'], 'WeightedEnsemble_L3': ['WeightedEnsemble_L3']}, 'model_fit_times': {'LightGBMXT_BAG_L1': 56.714457750320435, 'LightGBM_BAG_L1': 51.43827152252197, 'RandomForestMSE_BAG_L1': 120.37472534179688, 'CatBoost_BAG_L1': 37.85995078086853, 'WeightedEnsemble_L2': 0.15986418724060059, 'LightGBMXT_BAG_L2': 55.29365634918213, 'LightGBM_BAG_L2': 52.654309034347534, 'WeightedEnsemble_L3': 0.2106790542602539}, 'model_pred_times': {'LightGBMXT_BAG_L1': 1.4272074699401855, 'LightGBM_BAG_L1': 0.6877648830413818, 'RandomForestMSE_BAG_L1': 6.528245449066162, 'CatBoost_BAG_L1': 0.16579270362854004, 'WeightedEnsemble_L2': 0.0031926631927490234, 'LightGBMXT_BAG_L2': 0.8342902660369873, 'LightGBM_BAG_L2': 0.45854926109313965, 'WeightedEnsemble_L3': 0.0028324127197265625}, 'num_bag_folds': 8, 'max_stack_level': 3, 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'RandomForestMSE_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True, 'use_child_oof': True}, 'CatBoost_BAG_L1': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBMXT_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'LightGBM_BAG_L2': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'WeightedEnsemble_L3': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                     model     score_val              eval_metric  \\\n",
      "0     WeightedEnsemble_L3 -72768.336340  root_mean_squared_error   \n",
      "1       LightGBMXT_BAG_L2 -72819.671931  root_mean_squared_error   \n",
      "2     WeightedEnsemble_L2 -72821.825567  root_mean_squared_error   \n",
      "3       LightGBMXT_BAG_L1 -72879.577450  root_mean_squared_error   \n",
      "4         LightGBM_BAG_L1 -73158.421654  root_mean_squared_error   \n",
      "5         LightGBM_BAG_L2 -73196.013646  root_mean_squared_error   \n",
      "6         CatBoost_BAG_L1 -76402.032339  root_mean_squared_error   \n",
      "7  RandomForestMSE_BAG_L1 -77194.901115  root_mean_squared_error   \n",
      "\n",
      "   pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0      10.104682  374.546050                0.002832           0.210679   \n",
      "1       9.643301  321.681062                0.834290          55.293656   \n",
      "2       8.646410  228.687319                0.003193           0.159864   \n",
      "3       1.427207   56.714458                1.427207          56.714458   \n",
      "4       0.687765   51.438272                0.687765          51.438272   \n",
      "5       9.267560  319.041714                0.458549          52.654309   \n",
      "6       0.165793   37.859951                0.165793          37.859951   \n",
      "7       6.528245  120.374725                6.528245         120.374725   \n",
      "\n",
      "   stack_level  can_infer  fit_order  \n",
      "0            3       True          8  \n",
      "1            2       True          6  \n",
      "2            2       True          5  \n",
      "3            1       True          1  \n",
      "4            1       True          2  \n",
      "5            2       True          7  \n",
      "6            1       True          4  \n",
      "7            1       True          3  }\n",
      "                    model     score_val              eval_metric  \\\n",
      "0     WeightedEnsemble_L3 -72768.336340  root_mean_squared_error   \n",
      "1       LightGBMXT_BAG_L2 -72819.671931  root_mean_squared_error   \n",
      "2     WeightedEnsemble_L2 -72821.825567  root_mean_squared_error   \n",
      "3       LightGBMXT_BAG_L1 -72879.577450  root_mean_squared_error   \n",
      "4         LightGBM_BAG_L1 -73158.421654  root_mean_squared_error   \n",
      "5         LightGBM_BAG_L2 -73196.013646  root_mean_squared_error   \n",
      "6         CatBoost_BAG_L1 -76402.032339  root_mean_squared_error   \n",
      "7  RandomForestMSE_BAG_L1 -77194.901115  root_mean_squared_error   \n",
      "\n",
      "   pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0      10.104682  374.546050                0.002832           0.210679   \n",
      "1       9.643301  321.681062                0.834290          55.293656   \n",
      "2       8.646410  228.687319                0.003193           0.159864   \n",
      "3       1.427207   56.714458                1.427207          56.714458   \n",
      "4       0.687765   51.438272                0.687765          51.438272   \n",
      "5       9.267560  319.041714                0.458549          52.654309   \n",
      "6       0.165793   37.859951                0.165793          37.859951   \n",
      "7       6.528245  120.374725                6.528245         120.374725   \n",
      "\n",
      "   stack_level  can_infer  fit_order  \n",
      "0            3       True          8  \n",
      "1            2       True          6  \n",
      "2            2       True          5  \n",
      "3            1       True          1  \n",
      "4            1       True          2  \n",
      "5            2       True          7  \n",
      "6            1       True          4  \n",
      "7            1       True          3  \n"
     ]
    }
   ],
   "source": [
    "# Print model performance\n",
    "results = predictor.fit_summary()\n",
    "print(results)\n",
    "\n",
    "# Get leaderboard\n",
    "lb = predictor.leaderboard()\n",
    "print(lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917a9fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:20:48.059040Z",
     "iopub.status.busy": "2024-09-03T20:20:48.058272Z",
     "iopub.status.idle": "2024-09-03T20:21:01.189043Z",
     "shell.execute_reply": "2024-09-03T20:21:01.188008Z"
    },
    "papermill": {
     "duration": 13.317304,
     "end_time": "2024-09-03T20:21:01.191341",
     "exception": false,
     "start_time": "2024-09-03T20:20:47.874037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20240903_201044/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20240903_201044/models/WeightedEnsemble_L3/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test data\n",
    "test_predictions = predictor.predict(test_df)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'price': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ca3bde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-03T20:21:01.558100Z",
     "iopub.status.busy": "2024-09-03T20:21:01.557321Z",
     "iopub.status.idle": "2024-09-03T20:21:01.567353Z",
     "shell.execute_reply": "2024-09-03T20:21:01.566408Z"
    },
    "papermill": {
     "duration": 0.193348,
     "end_time": "2024-09-03T20:21:01.569420",
     "exception": false,
     "start_time": "2024-09-03T20:21:01.376072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188533</td>\n",
       "      <td>18465.087891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188534</td>\n",
       "      <td>82734.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188535</td>\n",
       "      <td>55964.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188536</td>\n",
       "      <td>35058.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188537</td>\n",
       "      <td>30713.298828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         price\n",
       "0  188533  18465.087891\n",
       "1  188534  82734.875000\n",
       "2  188535  55964.460938\n",
       "3  188536  35058.062500\n",
       "4  188537  30713.298828"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7e630",
   "metadata": {
    "papermill": {
     "duration": 0.177822,
     "end_time": "2024-09-03T20:21:01.935658",
     "exception": false,
     "start_time": "2024-09-03T20:21:01.757836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9057646,
     "sourceId": 76728,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 920.755589,
   "end_time": "2024-09-03T20:21:07.235224",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-03T20:05:46.479635",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
